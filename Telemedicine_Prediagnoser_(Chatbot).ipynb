{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WoZwru12RVaU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "#Loading Data\n",
        "with open(\"intents.json\") as file:\n",
        "\tdata = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlUOHdiuUMPo",
        "outputId": "256307b8-490a-4526-b05a-5b5e5fd192e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "db1k_zgXElK_"
      },
      "outputs": [],
      "source": [
        "docs_x = []\n",
        "docs_y = []\n",
        "labels= []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rD7tS1SiT4Fd"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "#from nltk.stem.lancaster import LancasterStemmer\n",
        "\n",
        "#stemming good?\n",
        "#stemmer = LancasterStemmer()\n",
        "rt = RegexpTokenizer(r'[^\\W_]+|[^\\W_\\s]+')\n",
        "stop = set(stopwords.words('english') + list(string.punctuation))\n",
        "#Looping through our data\n",
        "for intent in data['intents']:\n",
        "  words = []\n",
        "  for pattern in intent['patterns']:\n",
        "    pattern = pattern.lower()\n",
        "    #print(pattern)\n",
        "    #Creating a list of words\n",
        "    ###wrds = rt.tokenize(pattern)\n",
        "    wrds = [i for i in rt.tokenize(pattern) if i not in stop]\n",
        "    words.append(wrds)\n",
        "  docs_x.append(words)\n",
        "  docs_y.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMasM6lIjbkY",
        "outputId": "587ada10-f27f-4af0-e15f-3853e1f03095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[['skin', 'rash'], ['dischromic', 'patches'], ['itching'], ['nodal', 'skin', 'eruptions']], [['chills'], ['shivering'], ['continuous', 'sneezing']], [['vomiting'], ['chest', 'pain'], ['acidity'], ['ulcers', 'tongue'], ['stomach', 'pain'], ['cough']], [['vomiting'], ['nausea'], ['yellowish', 'skin'], ['abdominal', 'pain'], ['loss', 'appetite'], ['yellowing', 'eyes'], ['itching']], [['burning', 'micturition'], ['skin', 'rash'], ['spotting', 'urination'], ['stomach', 'pain'], ['itching']], [['vomiting'], ['indigestion'], ['passage', 'gases'], ['loss', 'appetite'], ['abdominal', 'pain'], ['internal', 'itching']], [['extra', 'marital', 'contacts'], ['patches', 'throat'], ['high', 'fever'], ['muscle', 'wasting']], [['lethargy'], ['increased', 'appetite'], ['fatigue'], ['obesity'], ['irregular', 'sugar', 'level'], ['restlessness'], ['weight', 'loss'], ['blurred', 'distorted', 'vision'], ['excessive', 'hunger'], ['polyuria']], [['diarrhoea'], ['vomiting'], ['dehydration'], ['sunken', 'eyes']], [['high', 'fever'], ['breathlessness'], ['fatigue'], ['mucoid', 'sputum'], ['cough'], ['family', 'history']], [['lack', 'concentration'], ['headache'], ['chest', 'pain'], ['dizziness'], ['loss', 'balance']], [['indigestion'], ['stiff', 'neck'], ['irritability'], ['headache'], ['acidity'], ['excessive', 'hunger'], ['blurred', 'distorted', 'vision'], ['depression'], ['visual', 'disturbances']], [['weakness', 'limbs'], ['back', 'pain'], ['dizziness'], ['neck', 'pain'], ['loss', 'balance']], [['headache'], ['vomiting'], ['weakness', 'one', 'body', 'side'], ['altered', 'sensorium']], [['vomiting'], ['high', 'fever'], ['fatigue'], ['yellowish', 'skin'], ['dark', 'urine'], ['abdominal', 'pain'], ['weight', 'loss'], ['itching']], [['vomiting'], ['high', 'fever'], ['nausea'], ['sweating'], ['headache'], ['muscle', 'pain'], ['diarrhoea'], ['chills']], [['high', 'fever'], ['lethargy'], ['fatigue'], ['headache'], ['loss', 'appetite'], ['mild', 'fever'], ['red', 'spots', 'body'], ['malaise'], ['skin', 'rash'], ['swelled', 'lymph', 'nodes'], ['itching']], [['vomiting'], ['high', 'fever'], ['joint', 'pain'], ['nausea'], ['pain', 'behind', 'eyes'], ['fatigue'], ['headache'], ['back', 'pain'], ['muscle', 'pain'], ['loss', 'appetite'], ['red', 'spots', 'body'], ['malaise'], ['skin', 'rash'], ['chills']], [['vomiting'], ['high', 'fever'], ['nausea'], ['fatigue'], ['headache'], ['abdominal', 'pain'], ['belly', 'pain'], ['constipation'], ['toxic', 'look', 'typhos'], ['diarrhoea'], ['chills']], [['vomiting'], ['joint', 'pain'], ['nausea'], ['muscle', 'pain'], ['yellowish', 'skin'], ['dark', 'urine'], ['loss', 'appetite'], ['abdominal', 'pain'], ['mild', 'fever'], ['diarrhoea'], ['yellowing', 'eyes']], [['lethargy'], ['fatigue'], ['yellowish', 'skin'], ['dark', 'urine'], ['loss', 'appetite'], ['abdominal', 'pain'], ['receiving', 'unsterile', 'injections'], ['receiving', 'blood', 'transfusion'], ['yellow', 'urine'], ['malaise'], ['yellowing', 'eyes'], ['itching']], [['nausea'], ['fatigue'], ['yellowish', 'skin'], ['loss', 'appetite'], ['yellowing', 'eyes'], ['family', 'history']], [['vomiting'], ['joint', 'pain'], ['nausea'], ['fatigue'], ['yellowish', 'skin'], ['dark', 'urine'], ['loss', 'appetite'], ['abdominal', 'pain'], ['yellowing', 'eyes']], [['vomiting'], ['high', 'fever'], ['joint', 'pain'], ['nausea'], ['fatigue'], ['yellowish', 'skin'], ['dark', 'urine'], ['loss', 'appetite'], ['abdominal', 'pain'], ['stomach', 'bleeding'], ['acute', 'liver', 'failure'], ['coma'], ['yellowing', 'eyes']], [['vomiting'], ['fluid', 'overload'], ['swelling', 'stomach'], ['history', 'alcohol', 'consumption'], ['yellowish', 'skin'], ['abdominal', 'pain'], ['distention', 'abdomen']], [['vomiting'], ['high', 'fever'], ['breathlessness'], ['sweating'], ['blood', 'sputum'], ['fatigue'], ['chest', 'pain'], ['phlegm'], ['loss', 'appetite'], ['mild', 'fever'], ['weight', 'loss'], ['malaise'], ['swelled', 'lymph', 'nodes'], ['yellowing', 'eyes'], ['chills'], ['cough']], [['high', 'fever'], ['sinus', 'pressure'], ['continuous', 'sneezing'], ['fatigue'], ['headache'], ['congestion'], ['chest', 'pain'], ['phlegm'], ['runny', 'nose'], ['muscle', 'pain'], ['loss', 'smell'], ['throat', 'irritation'], ['malaise'], ['swelled', 'lymph', 'nodes'], ['chills'], ['cough'], ['redness', 'eyes']], [['high', 'fever'], ['breathlessness'], ['sweating'], ['fatigue'], ['chest', 'pain'], ['rusty', 'sputum'], ['phlegm'], ['fast', 'heart', 'rate'], ['malaise'], ['chills'], ['cough']], [['pain', 'anal', 'region'], ['bloody', 'stool'], ['pain', 'bowel', 'movements'], ['constipation'], ['irritation', 'anus']], [['vomiting'], ['breathlessness'], ['sweating']], [['fatigue'], ['cramps'], ['obesity'], ['swollen', 'legs'], ['prominent', 'veins', 'calf'], ['bruising'], ['swollen', 'blood', 'vessels']], [['puffy', 'face', 'eyes'], ['lethargy'], ['irritability'], ['fatigue'], ['enlarged', 'thyroid'], ['cold', 'hands', 'feets'], ['dizziness'], ['weight', 'gain'], ['depression'], ['mood', 'swings'], ['swollen', 'extremeties'], ['abnormal', 'menstruation'], ['brittle', 'nails']], [['irritability'], ['sweating'], ['fatigue'], ['muscle', 'weakness'], ['excessive', 'hunger'], ['restlessness'], ['weight', 'loss'], ['fast', 'heart', 'rate'], ['diarrhoea'], ['mood', 'swings'], ['abnormal', 'menstruation']], [['vomiting'], ['nausea'], ['sweating'], ['irritability'], ['fatigue'], ['headache'], ['drying', 'tingling', 'lips'], ['excessive', 'hunger'], ['palpitations'], ['blurred', 'distorted', 'vision'], ['slurred', 'speech'], ['anxiety']], [['swelling', 'joints'], ['joint', 'pain'], ['hip', 'joint', 'pain'], ['painful', 'walking'], ['knee', 'pain'], ['neck', 'pain']], [['swelling', 'joints'], ['stiff', 'neck'], ['painful', 'walking'], ['muscle', 'weakness'], ['movement', 'stiffness']], [['vomiting'], ['nausea'], ['headache'], ['unsteadiness'], ['spinning', 'movements'], ['loss', 'balance']], [['skin', 'rash'], ['blackheads'], ['scurring'], ['pus', 'filled', 'pimples']], [['foul', 'smell', 'urine'], ['burning', 'micturition'], ['bladder', 'discomfort'], ['continuous', 'feel', 'urine']], [['joint', 'pain'], ['skin', 'peeling'], ['silver', 'like', 'dusting'], ['inflammatory', 'nails'], ['skin', 'rash'], ['small', 'dents', 'nails']], [['high', 'fever'], ['blister'], ['red', 'sore', 'around', 'nose'], ['yellow', 'crust', 'ooze'], ['skin', 'rash']]]\n",
            "['Fungal infection', 'Allergy', 'GERD', 'Chronic cholestasis', 'Drug Reaction', 'Peptic ulcer diseae', 'AIDS', 'Diabetes ', 'Gastroenteritis', 'Bronchial Asthma', 'Hypertension ', 'Migraine', 'Cervical spondylosis', 'Paralysis (brain hemorrhage)', 'Jaundice', 'Malaria', 'Chicken pox', 'Dengue', 'Typhoid', 'hepatitis A', 'Hepatitis B', 'Hepatitis C', 'Hepatitis D', 'Hepatitis E', 'Alcoholic hepatitis', 'Tuberculosis', 'Common Cold', 'Pneumonia', 'Dimorphic hemmorhoids(piles)', 'Heart attack', 'Varicose veins', 'Hypothyroidism', 'Hyperthyroidism', 'Hypoglycemia', 'Osteoarthristis', 'Arthritis', '(vertigo) Paroymsal  Positional Vertigo', 'Acne', 'Urinary tract infection', 'Psoriasis', 'Impetigo']\n",
            "41\n"
          ]
        }
      ],
      "source": [
        "print(docs_x)\n",
        "print(docs_y)\n",
        "print(len(docs_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLQ6MXWOXJeL",
        "outputId": "8be45d4e-1562-4eeb-c905-ed589bb5ea8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (862182613 of 862182613) |##########| Elapsed Time: 0:02:40 Time:  0:02:40\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('glove.6B.zip', <http.client.HTTPMessage at 0x7ffa6b417e50>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import progressbar\n",
        "import urllib.request\n",
        "\n",
        "pbar = None\n",
        "def show_progress(block_num, block_size, total_size):\n",
        "    global pbar\n",
        "    if pbar is None:\n",
        "        pbar = progressbar.ProgressBar(maxval=total_size)\n",
        "        pbar.start()\n",
        "\n",
        "    downloaded = block_num * block_size\n",
        "    if downloaded < total_size:\n",
        "        pbar.update(downloaded)\n",
        "    else:\n",
        "        pbar.finish()\n",
        "        pbar = None\n",
        "\n",
        "\n",
        "#urllib.request.urlretrieve(model_url, model_file, show_progress)\n",
        "urllib.request.urlretrieve('https://nlp.stanford.edu/data/glove.6B.zip','glove.6B.zip', show_progress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhereHcyfkt1",
        "outputId": "0adb9683-5943-4521-eb1f-9944e2d16062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: /content/glove.6B.50d.txt  \n",
            "  inflating: /content/glove.6B.100d.txt  \n",
            "  inflating: /content/glove.6B.200d.txt  \n",
            "  inflating: /content/glove.6B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/glove.6B.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B2Sl1C3ZQZ2",
        "outputId": "170355f0-05c1-4206-aec7-12b253f578d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings_index = dict()\n",
        "f = open('./glove.6B.300d.txt')\n",
        "\n",
        "for line in f:\n",
        "    word, coefs = line.split(maxsplit=1)\n",
        "    coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XlO6XgVtZrWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a004e4-94a3-4aa3-ba96-fd4e138d62cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n"
          ]
        }
      ],
      "source": [
        "#testing embeddings\n",
        "\n",
        "embedding_vector = embeddings_index.get(\"ulcer\")\n",
        "print(embedding_vector.shape)\n",
        "arr = np.zeros(300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF69clZdacgi",
        "outputId": "958c9b15-e62b-4fe3-8cfd-e1f2b2e4873d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n",
            "17\n",
            "543\n"
          ]
        }
      ],
      "source": [
        "diseases = 0\n",
        "word_count = 0\n",
        "max_symptoms_count = 0\n",
        "for symptoms_of_1_disease in docs_x:\n",
        "  diseases += 1\n",
        "  max_symptoms_count = max(max_symptoms_count, len(symptoms_of_1_disease))\n",
        "  for individual_symptom in symptoms_of_1_disease:\n",
        "    for word in individual_symptom:\n",
        "      word_count+=1\n",
        "print(diseases)\n",
        "print(max_symptoms_count)\n",
        "print(word_count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KuHHnTiP_NM",
        "outputId": "139043c9-ad33-4d7f-8cb1-7ca695e5a387"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rkSAdO1qImb7"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import random\n",
        "\n",
        "class DataGen(keras.utils.all_utils.Sequence):\n",
        "    def __init__(self, docs_x, output, batch_size=8):\n",
        "        self.docs_x = docs_x\n",
        "        self.output = output\n",
        "        self.batch_size = batch_size\n",
        "        self.on_epoch_end()\n",
        "        self.hits=0\n",
        "        self.misses=0\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if((index+1)*self.batch_size > len(self.docs_x)):\n",
        "            self.batch_size = len(self.docs_x) - index*self.batch_size\n",
        "        \n",
        "        inp_batch = self.docs_x[index*self.batch_size : (index+1)*self.batch_size]\n",
        "        #print()\n",
        "        inp_batch_embeddings = [] #np.zeros(shape = (self.batch_size, max_symptoms_count, 300))\n",
        "        for symptoms_of_1_disease in inp_batch:\n",
        "          random.shuffle(symptoms_of_1_disease)\n",
        "          symptoms_embedding = np.zeros((len(symptoms_of_1_disease), 300))\n",
        "          j = 0\n",
        "          for individual_symptom in symptoms_of_1_disease:\n",
        "            individual_symptom_embedding = np.zeros(300)\n",
        "            for word in individual_symptom:\n",
        "              word_embedding = embeddings_index.get(word)\n",
        "              if word_embedding is not None:\n",
        "                self.hits += 1\n",
        "                individual_symptom_embedding += word_embedding\n",
        "              else:\n",
        "                self.misses += 1\n",
        "            symptoms_embedding[j] = individual_symptom_embedding #new code add padding using DataGen later\n",
        "            j = j + 1\n",
        "          symptoms_embedding = np.pad(symptoms_embedding, [((max_symptoms_count - symptoms_embedding.shape[0]), 0), (0, 0)], mode='constant', constant_values=0)\n",
        "          inp_batch_embeddings.append(symptoms_embedding)\n",
        "        \n",
        "        inp_batch_embeddings = np.array(inp_batch_embeddings)\n",
        "\n",
        "        out_batch = self.output[index*self.batch_size : (index+1)*self.batch_size]\n",
        "     \n",
        "        return inp_batch_embeddings, out_batch\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.docs_x)/float(self.batch_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_Oj7Zrv25Eq",
        "outputId": "83d6d594-5489-49c3-e4ab-417d892f9b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15  4 16  9 14 33  1 12 17  6 23 30  7 32 28 29  8 11 37 40 19 20 21 22\n",
            "  3 36 10 34 13 18 39 26 24 25 31  5  0  2 38 35 27]\n"
          ]
        }
      ],
      "source": [
        "#label encoding y axis\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()  \n",
        "y =  label_encoder.fit_transform(docs_y)\n",
        "y= np.asarray(y)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EvLpA0EkwrkO"
      },
      "outputs": [],
      "source": [
        "# from keras.models import *\n",
        "# from keras.layers import *\n",
        "\n",
        "# def define_model():\n",
        "#     input1 = Input(shape=(max_symptoms_count,300)) \n",
        "#     lstm1 = Bidirectional(LSTM(units=128))(input1)\n",
        "#     dnn_hidden_layer1 = Dense(64, activation='relu')(lstm1) \n",
        "#     dnn_output = Dense(41, activation='softmax')(dnn_hidden_layer1)\n",
        "#     model = Model(inputs=[input1],outputs=[dnn_output])\n",
        "#     # compile the model\n",
        "#     model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#     model.summary()\n",
        "#     return model\n",
        "# model = define_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add attention layer to the deep learning network\n",
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "from keras import Model\n",
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Dense, SimpleRNN,LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.metrics import mean_squared_error\n",
        "\n",
        "class attention(Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(attention,self).__init__(**kwargs)\n",
        " \n",
        "    def build(self,input_shape):\n",
        "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n",
        "                               initializer='random_normal', trainable=True)\n",
        "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n",
        "                               initializer='zeros', trainable=True)        \n",
        "        super(attention, self).build(input_shape)\n",
        " \n",
        "    def call(self,x):\n",
        "        # Alignment scores. Pass them through tanh function\n",
        "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
        "        # Remove dimension of size 1\n",
        "        e = K.squeeze(e, axis=-1)   \n",
        "        # Compute the weights\n",
        "        alpha = K.softmax(e)\n",
        "        # Reshape to tensorFlow format\n",
        "        alpha = K.expand_dims(alpha, axis=-1)\n",
        "        # Compute the context vector\n",
        "        context = x * alpha\n",
        "        context = K.sum(context, axis=1)\n",
        "        return context\n",
        "def create_RNN_with_attention(hidden_units, dense_units, input_shape, activation):\n",
        "    x=Input(shape=input_shape)\n",
        "    RNN_layer = SimpleRNN(hidden_units, return_sequences=True, activation=activation)(x)\n",
        "    attention_layer = attention()(RNN_layer)\n",
        "    outputs=Dense(dense_units, trainable=True, activation=activation)(attention_layer)\n",
        "    model=Model(x,outputs)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])    \n",
        "    return model    \n",
        "def create_LSTM_with_attention(hidden_units, dense_units, input_shape, activation):\n",
        "    x=Input(shape=input_shape)\n",
        "    LSTM_layer = LSTM(hidden_units, return_sequences=True, activation='relu')(x)\n",
        "    attention_layer = attention()(LSTM_layer)\n",
        "    outputs=Dense(dense_units, trainable=True, activation=activation)(attention_layer)\n",
        "    model=Model(x,outputs)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])    \n",
        "    return model    \n",
        " \n",
        "model = create_LSTM_with_attention(hidden_units=256, dense_units=41, input_shape=(max_symptoms_count,300), activation='softmax')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WGJAITV1KPk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a7d938-831f-4eaa-b2ae-904792cc3bf4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 17, 300)]         0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 17, 256)           570368    \n",
            "                                                                 \n",
            " attention (attention)       (None, 256)               273       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 41)                10537     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 581,178\n",
            "Trainable params: 581,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IUijVcP1vE-",
        "outputId": "490c77df-4a8e-4d40-b00a-330ab3a3c300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 2s 44ms/step - loss: 3.7369 - accuracy: 0.0303\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.4742 - accuracy: 0.4000\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.5476 - accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.4739 - accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 3.8327 - accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 3.6234 - accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.8055 - accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 3.6131 - accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 3.5116 - accuracy: 0.4000\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 3.2445 - accuracy: 0.4000\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 3.6878 - accuracy: 0.2000\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 3.7322 - accuracy: 0.2000\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.2601 - accuracy: 0.2000\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 3.5625 - accuracy: 0.4000\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.9307 - accuracy: 0.6000\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 2.0181 - accuracy: 0.4000\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 3.6861 - accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 5.2545 - accuracy: 0.4000\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 2.3674 - accuracy: 0.4000\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.7346 - accuracy: 0.6000\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 3.1684 - accuracy: 0.4000\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.9476 - accuracy: 0.2000\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.7355 - accuracy: 0.8000\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.4531 - accuracy: 0.4000\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.8159 - accuracy: 0.2000\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.3790 - accuracy: 0.4000\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.0664 - accuracy: 0.6000\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.6043 - accuracy: 0.4000\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 3.2882 - accuracy: 0.4000\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.0920 - accuracy: 0.8000\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.8277 - accuracy: 0.8000\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.7159 - accuracy: 0.4000\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.6870 - accuracy: 0.6000\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 2.8235 - accuracy: 0.6000\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 5.2846 - accuracy: 0.4000\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 2.2357 - accuracy: 0.4000\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 2.2800 - accuracy: 0.4000\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.0188 - accuracy: 0.4000\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.1898 - accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 2.6615 - accuracy: 0.8000\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.2849 - accuracy: 0.8000\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.0386 - accuracy: 0.8000\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.9677 - accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.5222 - accuracy: 0.6000\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.3593 - accuracy: 0.6000\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.7789 - accuracy: 0.8000\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.1844 - accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.8110 - accuracy: 0.6000\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.9879 - accuracy: 0.6000\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 16.8325 - accuracy: 0.2000\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.8369 - accuracy: 0.6000\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.7670 - accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.9476 - accuracy: 0.8000\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 2.3424 - accuracy: 0.4000\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.7308 - accuracy: 0.8000\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 3.2904 - accuracy: 0.6000\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.2845 - accuracy: 0.6000\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.6140 - accuracy: 0.6000\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.3035 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6520 - accuracy: 0.8000\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.9595 - accuracy: 0.6000\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.4057 - accuracy: 0.8000\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 1.0416 - accuracy: 0.8000\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.6063 - accuracy: 0.8000\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 1.3105 - accuracy: 0.8000\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.0180 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.3611 - accuracy: 0.6000\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.5690 - accuracy: 0.4000\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.2729 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1.0865 - accuracy: 0.8000\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.7559 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2696 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.7591 - accuracy: 0.6000\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2833 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 2.9966 - accuracy: 0.4000\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 1.8316 - accuracy: 0.6000\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.7030 - accuracy: 0.8000\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.2976 - accuracy: 0.6000\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.7937 - accuracy: 0.4000\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 1.3652 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.4228 - accuracy: 0.8000\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4260 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.0712 - accuracy: 0.8000\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.7007 - accuracy: 0.8000\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1147 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1161 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5570 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0862 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.4784 - accuracy: 0.2000\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.8677 - accuracy: 0.8000\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.3390 - accuracy: 0.8000\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.6763 - accuracy: 0.8000\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5410 - accuracy: 0.8000\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2938 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.7914 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.0717 - accuracy: 0.6000\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.7694 - accuracy: 0.6000\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 1.1269 - accuracy: 0.8000\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.1438 - accuracy: 0.8000\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.8144 - accuracy: 0.6000\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.9999 - accuracy: 0.8000\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1977 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2754 - accuracy: 0.8000\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 1.1001 - accuracy: 0.6000\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.3816 - accuracy: 0.8000\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.2886 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2349 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.4002 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0973 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.5965 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 3.2502 - accuracy: 0.6000\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 4.0707 - accuracy: 0.8000\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.3693 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.4445 - accuracy: 0.8000\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.3402 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 1.0765 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.4083 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.9234 - accuracy: 0.8000\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5218 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 1.3248 - accuracy: 0.8000\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.1760 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.7729 - accuracy: 0.8000\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 1.1809 - accuracy: 0.8000\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6109 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5975 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5564 - accuracy: 0.8000\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2879 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4923 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5828 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 1.3470 - accuracy: 0.8000\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 1.0010 - accuracy: 0.8000\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 1.1230 - accuracy: 0.8000\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.3695 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0454 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5126 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.5277 - accuracy: 0.8000\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5764 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.8039 - accuracy: 0.8000\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.3219 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1141 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 2.5860 - accuracy: 0.6000\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2984 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6167 - accuracy: 0.8000\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.4990 - accuracy: 0.8000\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0562 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.4127 - accuracy: 0.8000\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2795 - accuracy: 0.8000\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.2431 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4280 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2273 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.3237 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 1.4930 - accuracy: 0.6000\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4412 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.5701 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5619 - accuracy: 0.8000\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1706 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1832 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1564 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0658 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1811 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1586 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.1619 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2552 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0865 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1914 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2749 - accuracy: 0.8000\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4450 - accuracy: 0.8000\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.9881 - accuracy: 0.6000\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1772 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.5745 - accuracy: 0.8000\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.1353 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.4522 - accuracy: 0.8000\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 5.1823 - accuracy: 0.6000\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.3541 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2531 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.3647 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1248 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4246 - accuracy: 0.8000\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.2342 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.1393 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.1203 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1069 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1745 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.2938 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4079 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0975 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.4343 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.5048 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.2405 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1713 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1831 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.0791 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4689 - accuracy: 0.8000\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1456 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "batch_size = 8\n",
        "train_gen = DataGen(\n",
        "    docs_x,\n",
        "    y,\n",
        "    batch_size,\n",
        "    )\n",
        "\n",
        "train_steps = len(docs_x)//batch_size\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=200,\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B4aFKt9N176s"
      },
      "outputs": [],
      "source": [
        "def predict_from_list(symptoms_of_1_disease):\n",
        "  hits = 0\n",
        "  misses = 0\n",
        "  symptoms_embedding = np.zeros((max_symptoms_count-len(symptoms_of_1_disease), 300))\n",
        "  for individual_symptom in symptoms_of_1_disease:\n",
        "    individual_symptom_embedding = np.zeros(300)\n",
        "    words = [i for i in rt.tokenize(individual_symptom) if i not in stop]\n",
        "    print(words)\n",
        "    for word in words:\n",
        "      word_embedding = embeddings_index.get(word)\n",
        "      if word_embedding is not None:\n",
        "        hits += 1\n",
        "        individual_symptom_embedding += word_embedding\n",
        "      else:\n",
        "        misses += 1\n",
        "    symptoms_embedding = np.append(symptoms_embedding, [individual_symptom_embedding], axis = 0)\n",
        "  #print(symptoms_embedding.shape)\n",
        "  print(f\"Of total words in symptoms: hits = {hits}, misses = {misses}, ratio = {hits/(hits+misses)}\")\n",
        "  test_data = np.array([symptoms_embedding])\n",
        "  print(test_data.shape)\n",
        "  pred = model.predict(test_data)\n",
        "  pos = np.argmax(pred, axis=1)\n",
        "  return label_encoder.inverse_transform([pos[0]])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixyQtjll3mzz",
        "outputId": "75b9da37-1401-49e8-8506-b0410bb7d0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter symptoms separated by space: muciod sputum, cough, family history, fatigue\n",
            "['muciod sputum', ' cough', ' family history', ' fatigue']\n",
            "['muciod', 'sputum']\n",
            "['cough']\n",
            "['family', 'history']\n",
            "['fatigue']\n",
            "Of total words in symptoms: hits = 5, misses = 1, ratio = 0.8333333333333334\n",
            "(1, 17, 300)\n",
            "\n",
            " Predicted disease: Bronchial Asthma\n"
          ]
        }
      ],
      "source": [
        "#lis = [\"indigestion\", \"stiff_neck\", \"irritability\",\"headache\", \"acidity\"]\n",
        "\n",
        "lis = [x for x in input(\"Enter symptoms separated by space: \").split(\",\")]\n",
        "print(lis)\n",
        "predicted_disease = predict_from_list(lis)\n",
        "print(f\"\\n Predicted disease: {predicted_disease}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YrNW4xWmKQWF"
      },
      "outputs": [],
      "source": [
        "def predict_from_sentence(symptoms):\n",
        "  print(symptoms)\n",
        "  hits = 0\n",
        "  misses = 0\n",
        "  symptoms_embedding = np.zeros((max_symptoms_count, 300))\n",
        "  words = [i for i in rt.tokenize(symptoms) if i not in stop]\n",
        "  print(words)\n",
        "  for word in words:\n",
        "    if hits == 17:\n",
        "      break\n",
        "    word_embedding = embeddings_index.get(word)\n",
        "    if word_embedding is not None:\n",
        "      hits += 1\n",
        "      symptoms_embedding[max_symptoms_count-hits] += word_embedding\n",
        "    else:\n",
        "      word_embedding = np.zeros(300)\n",
        "      misses += 1\n",
        "    \n",
        "  print(symptoms_embedding.shape)\n",
        "  print(f\"Of total words in symptoms: hits = {hits}, misses = {misses}, ratio = {hits/(hits+misses)}\")\n",
        "  test_data = np.array([symptoms_embedding])\n",
        "  print(test_data.shape)\n",
        "  pred = model.predict(test_data)\n",
        "  pos = np.argmax(pred, axis=1)\n",
        "  return label_encoder.inverse_transform([pos[0]])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DGRB4X6Ldu8",
        "outputId": "5065dfbb-39a0-4aa7-b2e9-974750912a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i have skin rash dischromic patches itching and nodal skin eruptions\n",
            "['skin', 'rash', 'dischromic', 'patches', 'itching', 'nodal', 'skin', 'eruptions']\n",
            "(17, 300)\n",
            "Of total words in symptoms: hits = 7, misses = 1, ratio = 0.875\n",
            "(1, 17, 300)\n",
            "\n",
            " Predicted disease: Fungal infection\n"
          ]
        }
      ],
      "source": [
        "sentence = \"i have skin rash dischromic patches itching and nodal skin eruptions\"\n",
        "predicted_disease = predict_from_sentence(sentence)\n",
        "print(f\"\\n Predicted disease: {predicted_disease}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u7lFaLYGt9f"
      },
      "source": [
        "**Saving models**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "\n",
        "filehandler = open(\"./chatbot_v1\", 'wb') \n",
        "pickle.dump(model, filehandler)\n",
        "filehandler.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydHD7_PaiRON",
        "outputId": "d1d631c0-a849-496a-874e-26dde15cd9a1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://12e1fb93-2b0b-4576-91e8-33cde7af25ab/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://12e1fb93-2b0b-4576-91e8-33cde7af25ab/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9b77ed7490> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9b77e87110> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filehandler = open(\"./chatbot_v1\", 'rb') \n",
        "mo = pickle.load(filehandler)\n",
        "filehandler.close()\n",
        "print(mo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A9j69uoibYR",
        "outputId": "02b15738-434e-445e-94a3-6728a58a2afc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.functional.Functional object at 0x7f9b71c2c610>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vXweYVPOngXH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Telemedicine Prediagnoser (Chatbot).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}